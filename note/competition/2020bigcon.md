# 2020 빅콘테스트 챔피언리그: NS SHOP+ 판매실적 예측을 통한 편성 최적화 방안(모형) 도출
- 2020.07.20 ~ 2020.12.15
- 1차 PT서류심사, 2차 PT발표심사
- 우수상(빅데이터포럼의장상) 수상

## 갑작스럽게 참여했던 컴페티션, 가장 많은 계단을 올랐던 경험
- 졸업 선배의 권유로 시작하게 되었던 데이터 분석 관련 대회였다. 지금 생각해보면 크게 준비가 되어있지 않았던 상태로 참여한 대회였기에 여러가지로 내 무지와 부족함에 답답함도 많이 느꼇었다. 
- 그럼에도 불구하고 심사위원께서 좋게 봐주신 덕에 학부팀으로서는 이렇게 큰 대회에서 우수상(6/1500+)이라는 쾌거를 달성했고, 이 좁은 바닥에서 내 선배가 되어주신 주옥같은 분들을 많이 만났던 시간이었다.
- 나는 발표와 EDA 및 최적화 모형에 대해서 담당했고, 특히 컴페티션 기간동안 최적화만 주구장창 팠던 기억이 난다. 애초에 나는 공고에 붙어있던 "최적화"라는 한 단어에 꽃혀서 이 컴페티션의 권유를 수락했던 것이기에 팀에 누가 되지 않도록 논문도 많이 읽고, 구현도 하루에 몇천 줄씩 했던 기억이 난다.  
- 본선에 올라온 팀중 우리 팀만이 유일하게 메타휴리스틱으로 접근을 했었는데, 이게 생각보다 평가에서 엄청난 어드벤티지를 받았던 것으로 생각된다. 대부분의 팀이 터키 알고리즘이나 EDA를 통해서 최적화를 했었는데 그러한 접근보다는 차원이 좀 더 높았다고 생각한다.
<p align = 'center'>
   <img src = "https://github.com/koptimizer/description/blob/main/note/competition/pics/big1.jpg">
   (오프라인 시상식 진행으로 많이 아쉬웠지만 몹시 감격스러웠다 ㅎㅎ)
</p>

## EDA
- 나는 최적화 베이스 코드를 짜는 것을 주로 하고, EDA에서는 데이터 문해력이 좋은 팀원이 조달해준 시각화 과업이나 전처리를 처리해주는 것에 초점을 맞추었다.
- 솔직히 내가 EDA에 대해서 많이 감이 없었기에... 이 때에 어깨 너머로 많이 배웠다. 특히, 군집화를 통한 Feature Engineering이 어떻게 접근되어야 하는지에 대해서 많은 것들을 보고 배웠다. 
- 우리가 마주했던 가장 큰 문제는 Train Dataset에는 존재하지만 Test Dataset에는 존재하지 않는 마더코드와 상품명(상품코드)이 존재한다는 것이었는데, 이러한 것들을 Train Dataset과 매칭해주기 위해서 마더코드보다는 작고, 상품코드보다는 큰 단위의 중분류를 만들었다.
- 여기서 자연어 처리를 사용했는데, Konlpy를 이용해서 상품명을 토큰으로 잘라내고 W2V로 벡터화해서 각 토큰의 거리에 대한 연관 스코어 행렬을 구축하였다. 이렇게 하면 상품명이 비슷한 상품끼리 군집화가 되어 중분류 변수를 생성해줄 수 있다.
<p align = 'center'>
   <img src = "https://github.com/koptimizer/description/blob/main/note/competition/pics/big2.jpg">
</p>

- 또, 선배가 특제 소스(?)라고 말하던 Jenson-Shannon Divergence 기반의 군집화도 진행했다. 비슷한 매출액 추이를 보이는 상품끼리 묶어서 변수를 생성한 것인데, 홈쇼핑의 특성상 비슷한 매출액을 보이는 제품들이 특정한 연령층이나 성별과 관련이 되기 때문에 모델링에서 해당 변수가 큰 효용을 보였다.
<p align = 'center'>
   <img src = "https://github.com/koptimizer/description/blob/main/note/competition/pics/big3.jpg">
</p>

- 이외에도 Levenstein Distance를 이용해서 상품명의 특정 브랜드를 군집화 하거나 기후 상황과 같은 외부 데이터 셋도 사용했었는데, 외부 데이터 수집은 크롤링이 가능했던 내가 긁어다가 줬었다.
- 이렇게 대회 제출 약 이틀 전까지 거의 EDA만 주구장창 진행해서 초기 7개의 변수가 57개까지 부풀려졌었다. 최종적으로 csv로 변환된 파일을 눈으로 둘러보면서 이렇게 늘어난 변수에 뭔가 풍족한 느낌(?)을 받았는데, 이러한 느낌들이 압박감과 근심으로 거듭나기까지는 오래 걸리지 않았다...

## 모델링
- 대회 제출 이틀전 부터 숙소를 잡아서 팀원 전원이 크런치를 뛰었는데, 모델링이 대회 제출 4시간 전까지도 마무리가 안되어서(!!!) 최적화를 담당했던 나로서는 굉장히 난감했던 기억이 난다. 모델링이 되어야 최적화를 할 수 있기 때문...
- 모델링은 크게 별거 없었다. Gradeint Boosting이 해석하기에도 좋고 다중공선성 고려를 안해도 되니 GB의 프레임워크인 XGBoost와 LGBM을 사용했다. 다만, XGBoost가 Computational Time도 너무 길고 파라미터 튜닝하기에도 까다로워서 좀 더 가벼운 LGBM을 사용했다.
- 다행히 파라미터 최적화가 잘 마무리 되어서 대회 공식 지표인 MAPE도 잘 나왔기 때문에 최적화를 위한 실험시간 4시간(...)이 확보가 되었다. 내가 최적화를 돌리는 동안 나머지 팀원들이 변수 해석과 PT 제작을 맡아주었다. 
- 변수의 중요도를 해석하는 것은 당연하게도 SHAP Value와 Feature Importance를 사용했다. SHAP는 결과 지표의 관점에서 해당 변수가 얼마나 영향을 미치는지에 대한 지표이고, Feature Importance는 해당 변수가 트리의 분기에 얼마나 큰 관여를 하느냐에 대한 지표이다. 물론 둘 다 굉장히 중요한 지표이기 때문에 같이 언급하면 더 좋다.
<p align = 'center'>
   <img src = "https://github.com/koptimizer/description/blob/main/note/competition/pics/big4.jpg">
</p>

## 최적화
- 내가 실질적으로 깊게 공부해봤던 건 최적화 밖에 없으니, 대회 시작 때부터 최적화 파트는 아예 맡겨달라고 자부했었다. 남들이 EDA와 모델링에 주요하게 시간을 투자할 때에 나는 메타휴리스틱 논문을 읽고 실험을 해보면서 베이스 코드를 만들어왔다.
- 메타휴리스틱으로 접근을 하는 이유는 내게 익숙한 것도 있었지만, 이외에도 여러 가지들이 있다.
  - 방송편성표를 최적화하는 것은 조합최적화 문제로 근사될 수 있으며, n개의 홈쇼핑 편성에 대한 조합의 경우의 수는 n!이다. 대회에서는 한 달짜리 2892개의 항목에 대한 방송편성표의 최적화를 요구했기 때문에 경우의 수는 2892!가 된다. 이미 우주의 원자의 개수의 제곱은 아득히 뛰어넘는 양이기 때문에 일반적인 수리최적화로는 접근할 수 없다.
  - 때문에 근사적 전역최적화 방법인 메타휴리스틱으로 접근하면 광활한 해 공간에서도 만족할 만한 해를 탐색할 수 있겠다고 생각했다. 물론 비교적 쉬운 구현은 덤이다.
  - "강화학습을 적용하면 더 효과적이지 않냐?" 라고 물어본다면 "매우 비효율적이다"라고 대답하겠다. 강화학습을 사용하는 것은 연속적인 의사결정상황, 빠른 속도의 필요성, 제약의 복잡성이 크지 않는(남은 시간이 많지 않기 때문에...) 등의 상황에서 사용되어야 하는 방법인데, 한 달짜리 방송편성표 최적화는 연속적인 의사 결정과 거리가 멀고, 속도 문제도 큰 이슈가 되지 못한다. 결정적으로 제약이 많이 존재하기 때문에 복잡성이 너무 높아서 구현에 들어가야하는 시간과 노력이 매우 크게 필요하다.

### Cuckoo Search
- 조합최적화 문제를 풀기위한 이산적 메타휴리스틱 알고리즘하면 Genetic Algorithm 아니겠는가? 그런데... 못썻다... 변수가 너무 많은 덕에 가뜩이나 느린 GA가 더 힘겨워 하는게 느껴졌기 때문. 추가적으로 Mutation 단에서 방송편성표라는 도메인 상의 제약이 너무 많았기 때문에 Feasible을 지키면서 해의 Mutation을 일으키는 것에 큰 어려움이 존재했다.
<p align = 'center'>
   <img src = "https://github.com/koptimizer/description/blob/main/note/competition/pics/big5.jpg">
   </br>
   (지금봐도 머리가 아득해지는 해의 구성 요소들...)
</p>

- 그래서 좀 더 가벼운 메타휴리스틱 알고리즘을 찾았지만, 조합최적화를 완벽히 수행할 수 있는 이산 메타휴리스틱 알고리즘은 거의 없었고, 있더라도 훨씬 복잡했다.
- 결국 타겟으로 선정한 메타휴리스틱 알고리즘은 뻐꾸기 탐색법(Cuckoo Search)이었다. 뻐꾸기 탐색법은 뻐꾸기의 탁란(Brood Parasite)를 모사하여 전역 최적점을 찾아나가는 메타휴리스틱 알고리즘이다.
- 모든 메타휴리스틱 알고리즘은 탐색(Exploration)과 수렴(Exploitation)을 적절히 수행해야 하는데, 뻐꾸기 탐색법은 레비 비행 분포(Levy Flights Distribution)의 멱법칙(Power Law)을 이용해서 탐색과 착취를 수행한다.
- 레비 비행 분포는 꼬리가 두꺼운 지수 함수의 형태를 띄는데 이러한 성질 때문에 확률 변수를 생성할 경우 대부분의 결과는 몸통에 가깝게 발생하지만 두꺼운 꼬리에서도 어느정도 확률 변수가 발생하게 된다(멱법칙). 이를 이용해서 몸통쪽 결과가 발생하면 수렴을, 꼬리쪽에서 결과가 발생하면 탐색을 수행하는 것인데, 어찌보면 뻐꾸기 탐색법이라는 이름보다는 레비 탐색법이 어울린다고 볼 수 있다.
<p align = 'center'>
   <img src = "https://github.com/koptimizer/description/blob/main/note/competition/pics/big6.jpg">
   </br>
   (레비 비행 분포)
</p>

- 이 뻐꾸기 탐색이 매우 재밌는 것이 레비 비행 분포에서 확률 변수를 추출하는 것 하나만으로 탐색과 수렴을 모두 적절한 비율로 실행하는 매커니즘을 지내게 된다는 것이다.
- 다만 일반적인 뻐꾸기 탐색법은 연속적인 해에서만 가능하기 때문에 방송편성표와 같은 이산적인 해에서도 작동이 가능토록 하기 위해서 Ouaarab. A et al.(2012)의 논문을 참조해서 이산적인 뻐꾸기 탐색을 사용하였다.
- 해당 논문은 뻐꾸기 탐색법을 보부상 문제(Treveling Salesman Problem)에 적용하기 위해 이산적인 뻐꾸기 탐색법을 고안하였는데 방법 자체는 간단하다. 수렴을 해야하는 확률 변수가 발생하면 Two-Opt 기법을 사용해서 해를 변형시키고, 탐색을 해야하는 확률 변수가 발생하면 Double-Bridge 기법을 통해서 해를 변형시킨다.
<p align = 'center'>
   <img src = "https://github.com/koptimizer/description/blob/main/note/competition/pics/big7.jpg">
   </br>
   (Two Opt와 Double Bridge 기법)
</p>

- Double-bridge는 방송편성표에서는 충분히 탐색을 발생시킬 수 없기에 두 편성 사이의 모든 편성을 역으로 배열하는 식으로 응용하였다.
- 다행히 이런식으로 미리 베이스라인을 다듬어 두었기에 모델링이 많이 늦게 끝났어도 실험을 어느정도 진행해 볼 수 있었다. 다행히 EDA와 모델링에도 어느정도 참여하면서 제약조건을 완화시켜두었기 때문에 에러가 발생하지 않았고 2시간 동안 열심히 갈아가며 발표가 가능할 정도의 결과를 뽑아내고 부랴부랴 데드라인에 맞추어 제출을 했던 기억이 난다.
- 제안했던 뻐꾸기 탐색 스케쥴러를 andom Search 스케줄러와 비교했을 때에도 25~50% 까지 성능이 우수했다(이래봬도 최적화 쪽에서 Random의 강력함은 무시 못한다...). 다만 아쉬웠던 점은 역시 시간이 얼마 없었다 보니 충분히 실험을 해보지 못한 덕에 와! 대박! 정도의 결과를 뽑지 못했다는 것이다... 탐색 시간을 넉넉하게 줬으면 훨씬 더 잘 나왔을 텐데 했던 생각은 발표날 다른 팀의 최적화 성능을 보면서 사무치도록 났다. 
<p align = 'center'>
   <img src = "https://github.com/koptimizer/description/blob/main/note/competition/pics/big8.jpg">
   </br>
   (다행히 2시간만에 나왔던 최적화된 편성표 )
</p>

## 프레젠테이션
- 본선에서는 제출했던 PT자료로 발표를 하고 코드의 복원성까지 고려하여 심사위원 분들이 평가를 해주신다.
- 나는 발표를 썩 잘하지는 못한다. 때문에 원래는 선배가 발표를 할 예정이었다. 발표 경험도 많고 발성도 좋은 센빠이가 멋지게 피칭할 수 있도록 전적으로 서포트 할 생각이었다.
- 다만, 선배가 업무 폭탄에 빠져서 도저히 어렵겠다는 말씀에 총대를 맸다. 솔직히 허겁지겁 제출했던 PT자료는 지금 돌아보면 괴랄할 수준의 졸작이었기 때문에 선배도 본선에 갈 줄은 몰랐을 것이다...
- 이미 제출했던 PT 파일을 수정하는 것은 불가능하기에... 그냥 열심히 준비했다.. 정말 열심히...
- 중간에 발표자들을 위한 세미나 형식으로 전년도 수상자의 멘토링을 받았었는데 꽤나 도움이 되었었다. 특히, 어찌보면 당연한 이야기들이지만 많은 이들이 실수하는 부분을 집어주셨다. 기억에 남는 것이 있다면...
  - 타당하지 않은 서술 금지. ex) 캐글 커뮤니티에서 성능이 좋다고 해서 XGBoost 썻습니다.
  - 청중을 몰입을 깨지 않도록 주의. ex) 너무 많은 내용을 한꺼번에 서술, 논리적 흐름의 타당성 결여, 발표의 템포 등등...  
- 발표는 우리가 거의 마지막 순서라 2시간 이상을 기다렸었지만 순식간에 지나갔다. 주된 지적 내용으로는 예상대로 성능의 애매함을 얘기하셨는데, 솔직하게 얘기하기보단 접근 방법의 의의에 중요성을 두었다고 설명했다. 어떤 심사위원님은 Levenstein Distance로 브랜드 상품 군집화 하는 것에 대해서 예시를 들어주시며 타당성이 떨어진다는 지적을 해주셨는데... 거의 체크메이트라서 어쩔 수 없이 수긍을 해버리는 대참사를 발생시켰었다... 또르륵...
- 그러나 참으로 놀랍게도 본선 대상자로 선정되어 우수상까지 받아 인건비(?)는 건질 수 있었다. 물론 그 과정에 있어서 너무나도 많은 것들을 배운 시간이었기에 광탈을 했어도 두고두고 큰 배움이 되었을 것이다.
<p align = 'center'>
   <img src = "https://github.com/koptimizer/description/blob/main/note/competition/pics/big9.jpg">
   </br>
   (불안한 눈빛과... 그걸 지켜보는 심사위원... )
</p>






