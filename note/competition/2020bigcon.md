# 2020 빅콘테스트 챔피언리그: NS SHOP+ 판매실적 예측을 통한 편성 최적화 방안(모형) 도출
- 2020.07.20 ~ 2020.12.15

## 갑작스럽게 참여했던 컴페티션, 가장 많은 계단을 올랐던 발판
- 졸업 선배의 권유로 시작하게 되었던 데이터 분석 관련 대회였다. 지금 생각해보면 크게 준비가 되어있지 않았던 상태로 참여한 대회였기에 여러가지로 내 무지와 부족함에 답답함도 많이 느꼇던 것 같다. 
- 그럼에도 불구하고 심사위원분들이 좋게 봐주신 덕에 학부팀으로서 이렇게 큰 대회에서 우수상(6/1500+)이라는 쾌거를 달성했고, 이 좁은 바닥에서 내 인생의 선배가 되어주신 주옥같은 분들을 많이 만났던 시간이었다.
- 나는 발표와 EDA 및 최적화 모형에 대해서 담당했고, 특히 컴페티션 기간동안 최적화만 주구장창 팠던 기억이 난다. 애초에 나는 공고에 붙어있던 "최적화"라는 이 한 단어에 꽃혀서 이 컴페티션을 수락했던 것이기에 팀에 누가 되지 않도록 논문도 많이 읽고, 구현도 하루에 몇천 줄씩 했던 기억이 난다.  
- 평소에 메타휴리스틱에 관심이 많아서 구현도 많이 해보았고, 다양한 적용에 대한 논문도 많이 읽어왔던 터라 메타휴리스틱으로 접근을 했었는데, 이게 생각보다 평가에서 엄청난 어드벤티지를 받았던 것으로 생각된다. 대부분의 팀이 터키 알고리즘이나 EDA를 통해서 최적화를 했었는데 그러한 접근보다는 차원이 좀 더 높았다고 생각한다.

## EDA
- 솔직히 나는 EDA에 대해서 많이 약하다. 그래서 데이터 문해력이 좋은 팀원이 조달해준 시각화 과업이나 전처리를 처리해주는 것에 초점이 맞추어져 있었다.
- 그래서 어깨 너머로 많이 배웠었는데, 우선 첫 번째로 클러스터링을 통한 Feature Engineering이 어떻게 접근되어야 하는지에 대한 것이다.
- 우리가 마주했던 가장 큰 문제는 Train Dataset에는 존재하지만 Test Dataset에는 존재지 않는 마더코드와 상품명(상품코드)이 존재한다는 것이었는데, 이러한 것들을 Train Dataset과 매칭해주기 위해서 마더코드보다는 작고, 상품코드보다는 큰 단위의 중분류를 만들었다.
- 여기서 자연어 처리도 사용했었는데, Konlpy를 이용해서 상품명을 토큰화하고 W2V로 벡터화해서 거리에 대한 연관 스코어 행렬을 구축하였다. 이렇게 하면 상품명이 비슷한 상품끼리 군집화가 되어 중분류 변수를 생성해줄 수 있다.
- 또, 선배의 특제 소스(?)라고 말하건 Jenson-Shannon Divergence 기반의 군집화도 진행했다. 비슷한 매출액 추이를 보이는 상품끼리 묶어서 변수를 생성한 것인데, 실제로 모델링을 했을 때 이것을 한 것과 안 한 모델의 성능차이가 존재했었다.
- 이외에도 Levenstein Distance를 통한 클러스터링이나 기후상황과 같은 외부 데이터 셋도 사용했었는데, 외부 데이터 수집은 크롤링이 가능했던 내가 긁어다가 줬었다.

## 모델링
- EDA를 통해서 변수가 7개에서 57개까지 부풀려졌기 때문에 모델링에서 굉장히 많은 시간이 소요되었었다.
- 특히 모델링이 대회 하루 전까지도 마무리가 안되어서 최적화를 담당했던 나로서는 굉장히 난감했던 기억이 난다. 모델링이 되어야 최적화를 할 수 있기 때문...
- 
